import os
from typing import Callable, Tuple, Union
import torch
import pickle
import numpy as np
from .collision_checkers import CollisionChecker
from .kernel_perceptrons import DiffCo, MultiDiffCo
from . import kernel
from .model import Model
from .utils import euler2mat

def autogenerate_2d_dataset(
        dof: int,
        num_obstacles: int,
        label_type: str,
        env_name: str,
        num_init_points: int = 8000,
        link_length: float = 1.0,
        generate_random_cfgs: bool = True,
        random_seed: int = None) -> str:
    """Autogenerate a dataset using a default configuration that suits the
    desired task.
    
    Args:
        dof (int): Number of degrees of freedom.
        num_obstacles (int): Number of obstacles in the workspace.
        label_type (str): How to label the obstacles. Must be one of 'binary',
            'class', or 'instance'.
        env_name (str): Unique description to include in the filename.
        num_init_points (int): Number of init points.
        link_length (float): Robot link length. Defaults to 1.0.
        generate_random_cfgs (bool): Flag for generating random cfgs (defaults
            to True).
        random_seed (int): Random seed used to reproduce the same results,
            useful for debugging. Defaults to None.

    Returns:
        str: The path to the autogenerated dataset.
    """
    # Check if the dataset exists already
    output_dir = 'data/autogenerated'
    filename = f'2d_{dof}dof_{num_obstacles}obs_{label_type}_{env_name}.pt'
    dataset_filepath = os.path.join(output_dir, filename)
    if not os.path.exists(dataset_filepath):
        print(f'Autogenerating dataset at {dataset_filepath!r}')
        # FIXME: Rename 2d_data_generation.py so that it doesn't begin with a number (so we can import it like normal)
        dataset_generation = __import__('2d_data_generation')
        dataset_generation.main(env_name=env_name, folder=output_dir, label_type=label_type,
            dof=dof, num_init_points=num_init_points, link_length=link_length,
            generate_random_cfgs=generate_random_cfgs, random_seed=random_seed)
    else:
        print(f'Using previously autogenerated dataset at {dataset_filepath!r}')
    return dataset_filepath


def unpack_dataset(dataset_filepath: str) -> Tuple[Model, torch.Tensor, torch.Tensor, torch.Tensor, list]:
    """Load and unpack the dataset from file.

    Args:
        dataset_filepath (str): Path to dataset.

    Returns:
        diffco.model.Model: The robot model.
        torch.Tensor: The dataset "data".
        torch.Tensor: The labels.
        torch.Tensor: The dists.
        list: The obstacles.
    """
    dataset = torch.load(dataset_filepath)
    cfgs = dataset['data']
    labels = dataset['label']
    dists = dataset['dist']
    obstacles = dataset['obs']
    if 'rparam' in dataset:
        robot = dataset['robot'](*dataset['rparam'])
    else:
        robot = dataset['robot']()
    return robot, cfgs, labels, dists, obstacles

def load_dataset(filename: str, robot_name='2d', group=None, num_class=1):
    '''
    This was an old function for loading dataset from csv file.
    It is not used anymore.
    '''
    raise NotImplementedError
    # if filename.endswith('.pt'):
    #     return torch.load(filename)
    # elif filename.endswith('.csv'):
    #     dataset = {}
    #     all_data = torch.from_numpy(np.loadtxt(filename, delimiter=',', ndmin=2, dtype=np.float32))
    #     assert all_data.dtype in [torch.float32, torch.double]
    #     dataset['data'] = all_data[:, :-2*num_class]
    #     dataset['label'] = all_data[:, -2*num_class:-num_class]
    #     dataset['dist'] = all_data[:, -num_class:]
    #     dataset['obs'] = None
    #     if robot_name == 'panda':
    #         from .model import PandaFK
    #         dataset['robot'] = PandaFK
    #     elif robot_name == 'baxter' and group == 'left_arm':
    #         from .model import BaxterLeftArmFK
    #         dataset['robot'] = BaxterLeftArmFK
    #     elif robot_name == 'baxter' and group == 'both_arms':
    #         from .model import BaxterDualArmFK
    #         dataset['robot'] = BaxterDualArmFK
    #     else:
    #         raise NotImplementedError()
    # return dataset

def train_test_split(total_size: int, training_size: int) -> Tuple[torch.Tensor, torch.Tensor]:
    """Create indices for shuffling and splitting data into training/test sets.

    Args:
        total_size (int): The size of the dataset.
        training_size (int): The number of desired training data (test set size
            is total_size - training_size).
    
    Returns:
        torch.Tensor: The training set indices.
        torch.Tensor: The test set indices.
    """
    shuffled_indices = torch.LongTensor(np.random.choice(total_size, total_size, replace=False))
    train_indices = shuffled_indices[:training_size]
    test_indices = shuffled_indices[training_size:]
    return train_indices, test_indices

def generate_unified_grid(width: int = 400, height: int = 400) -> torch.Tensor:
    """Generate uniformly distributed grid points. DiffCo can be more accurately
    compared with FCL's performance when a grid like this is used for inference.

    Args:
        width (int): The width of the grid (number of points). Defaults to 400.
        height (int): The height of the grid (number of points). Usually the
            grid is square, so height should be the same as width. Defaults to
            400.

    Returns:
        torch.Tensor: The grid points.
    """
    yy, xx = torch.meshgrid(torch.linspace(-np.pi, np.pi, width), torch.linspace(-np.pi, np.pi, height), indexing='ij')
    grid_points = torch.stack([xx, yy], axis=2).reshape((-1, 2))
    return grid_points

def load_pretrained_checker(filepath: str) -> CollisionChecker:
    """If provided, the training phase is skipped and the pretrained checker is
    used instead (may provide a speedup).

    Args:
        filepath (str): Path to a pretrained collision checker.
    
    Returns:
        diffco.CollisionChecker: The pretrained checker.
    """
    with open(filepath, 'rb') as f:
        checker = pickle.load(f)
        print('checker loaded: {}'.format(f.name))
    return checker

def train_checker(
        checker_type: CollisionChecker,
        train_data: torch.Tensor,
        train_labels: torch.Tensor,
        train_dists: torch.Tensor,
        fkine: Union[Callable, None],
        obstacles: list,
        trained_checker_dump: str,
        lmbda=10) -> CollisionChecker:
    """Train a collision checker.

    Args:
        checker_type (CollisionChecker): The collision checker class.
        train_data (torch.Tensor): The training data.
        train_labels (torch.Tensor): The training data labels.
        train_dists (torch.Tensor): The training data dists.
        fkine (Callable | None): The forward kinematics method (could be None).
        obstacles (list): The obstacles.
        trained_dump_filename (str): The filename for the trained checker dump.
        lmbda (float): Argument passed to RQKernel when training a new collision
            checker. Defaults to 10.
    
    Returns:
        diffco.CollisionChecker: The trained collision checker.
    """
    # kernel_func = kernel.FKKernel(fkine, kernel.RQKernel(lmbda)) if fkine is not None else kernel.RQKernel(lmbda)
    kernel_func = kernel.RQKernel(lmbda)
    checker = checker_type(kernel_func=kernel_func, beta=1.0, transform=fkine) 
    checker.train(train_data, train_labels, max_iteration=len(train_data), distance=train_dists, verbose=True)
    if trained_checker_dump is not None:
        # os.makedirs('results', exist_ok=True)
        # with open(os.path.join('results', f'{trained_checker_dump}.p'), 'wb') as f:
        with open(trained_checker_dump, 'wb') as f:
            pickle.dump(checker, f)
            print('checker saved: {}'.format(f.name))
    return checker

def fit_checker(
        checker: CollisionChecker,
        kernel_type: kernel.KernelFunc = kernel.Polyharmonic,
        fit_full_poly: bool = False,
        fitting_target: str = 'label',
        fitting_epsilon: float = 0.01,
        fkine: Callable = None) -> None:
    """Fit the collision checker.

    Args:
        checker (CollisionChecker): The trained collision checker.
        kernel_type (KernelFunc): The type of kernel function to use when
            fit_full_poly is False. Currently supported kernel types are
            Polyharmonic and MultiQuadratic.
        fit_full_poly (bool): When True, uses the collision checkers
            fit_full_poly fitting function. When False (default), uses the
            fit_poly fitting function.
        fitting_target (str): The fitting target. Must be one of the following:
            'label', 'dist', or 'hypo'. Defaults to 'label'.
        fitting_epsilon (float): Argument passed to the checker's fit function.
            Defaults to 0.01.
        fkine (Callable): The forward kinematics method (defaults to None).
    """
    if fit_full_poly:
        checker.fit_full_poly(epsilon=fitting_epsilon, k=3, target=fitting_target)
    else:
        if kernel_type == kernel.Polyharmonic:
            kernel_func = kernel.Polyharmonic(1, fitting_epsilon)
        elif kernel_type == kernel.MultiQuadratic:
            kernel_func = kernel.MultiQuadratic(fitting_epsilon)
        else:
            raise NotImplementedError(kernel_type)
        checker.fit_poly(kernel_func=kernel_func, target=fitting_target)

def get_estimator(checker: CollisionChecker, scoring_method: str = 'rbf_score') -> Callable:
    """Get estimator using the desired scoring method.

    Args:
        checker (CollisionChecker): The trained collision checker.
        scoring_method (str): Scoring method for the collision checker.
            Supported scoring methods are 'rbf_score', 'poly_score', and
            'score'. Defaults to 'rbf_score'.
    Returns:
        Callable: The corresponding scoring method.
    """
    if scoring_method == 'poly_score':
        return checker.poly_score
    if scoring_method == 'full_poly_score':
        return checker.full_poly_score
    if scoring_method == 'score':
        return checker.score
    raise NotImplementedError(scoring_method)

def test_checker(
        checker: CollisionChecker,
        dist_est: Callable,
        test_data: torch.Tensor,
        test_labels: torch.Tensor,
        safety_margin: float = 0) -> None:
    """Run a trained collision checker on the test set and print results.

    Args:
        checker (CollisionChecker): The trained collision checker.
        dist_est (Callable): The distance estimator function.
        test_data (torch.Tensor): The test set data.
        test_labels (torch.Tensor): The test set labels.
        safety_margin (float): Amount to offset test predictions by when running
            the scoring method. Defaults to 0.
    """
    # Check DiffCo test ACC
    test_preds = (dist_est(test_data)-safety_margin > 0) * 2 - 1
    test_labels = test_labels.reshape(test_preds.shape)
    test_acc = torch.sum(test_preds == test_labels, dtype=torch.float32)/len(test_preds.view(-1))
    test_tpr = torch.sum(test_preds[test_labels ==1] == 1, dtype=torch.float32) / len(test_preds[test_labels ==1])
    test_tnr = torch.sum(test_preds[test_labels ==-1] == -1, dtype=torch.float32) / len(test_preds[test_labels==-1])
    print('Test acc: {:.4f}, TPR {:.4f}, TNR {:.4f}'.format(test_acc, test_tpr, test_tnr))
    print(len(checker.gains), 'Support Points')

def open3d_save_image(geoms, path):
    import open3d as o3d
    vis = o3d.visualization.Visualizer()
    vis.create_window(visible=False)
    for geom in geoms:
        vis.add_geometry(geom)
        vis.update_geometry(geom)
        vis.poll_events()
    vis.update_renderer()
    vis.capture_screen_image(path)
    vis.destroy_window()

def view_se3_path(robot, env_mesh, path):
    import trimesh
    rmeshes = []
    for i in range(len(path)):# torch.nonzero(fcl_preds.view(-1) == 1):
        r = euler2mat(path[i, 3:])[0].numpy()
        t = path[i, :3]
        tf = np.eye(4)
        tf[:3, :3] = r
        tf[:3, 3] = t
        r_mesh = robot.mesh.copy()
        r_mesh.apply_transform(tf)
        r_mesh.visual.vertex_colors = trimesh.visual.interpolate(r_mesh.vertices[:, 2], color_map='viridis')
        rmeshes.append(r_mesh)
    rmeshes[0].visual.vertex_colors = np.ones((len(rmeshes[0].vertices), 3)) * [0, 1, 0]
    rmeshes[-1].visual.vertex_colors = np.ones((len(rmeshes[-1].vertices), 3)) * [1, 1, 0]
    sum(rmeshes, env_mesh).show()

def save_ompl_path(filename, path):
    # input x, y, z, roll, pitch, yaw ('xyz' extrinsic convention euler angles)
    # output x,y,z,q1,q2,q3,w (scalar-last quaternions)
    from scipy.spatial.transform import Rotation
    # path = path.data.numpy()
    p_numpy = np.zeros((len(path), 7))
    p_numpy[:, :3] = path[:, :3]
    p_numpy[:, 3:] = Rotation.from_euler('xyz', path[:, 3:]).as_quat()
    # p_numpy[:, 3:] = Rotation.from_matrix(euler2mat(path[:, 3:]).numpy()).as_quat()
    with open(filename, 'w') as f:
        f.writelines([' '.join(map(str, cfg))+'\n' for cfg in p_numpy.tolist()])
        print('OMPL path saved in {}'.format(f.name))